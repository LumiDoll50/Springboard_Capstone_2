{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "cc5c7a47",
      "metadata": {
        "id": "cc5c7a47"
      },
      "source": [
        "# Capstone 2: Erasmus Program Mobility\n",
        "\n",
        "## Modeling\n",
        "\n",
        "## Table of Contents\n",
        "\n",
        "* [Load the Datasets](#load_datasets)\n",
        "    *  [Load X_train_no_scaling](#x_train_no_scaling)\n",
        "    *  [Load X_train_scaled](#x_train_scaled)\n",
        "    *  [Load X_test](#x_test)\n",
        "    *  [Load y_train](#y_train)\n",
        "    *  [Load y_test](#y_test)\n",
        "* [Model Evaluation - Linear Regression](#models_hyperparameters)\n",
        "    * [Define the Model and Hyperparameters](#models_hyperparameters)\n",
        "    * [Tune the Hyperparameters](#tune_hyperparameters)        \n",
        "        * [With Scaling](#evaluate_models)\n",
        "        * [Without Scaling](#evaluate_models)    \n",
        "* [Model Evaluation - Random Forest Regressor](#linear_regression)\n",
        "    * [Define the Model and Hyperparameters](#models_hyperparameters)\n",
        "    * [Tune the Hyperparameters](#tune_hyperparameters)        \n",
        "        * [With Scaling](#evaluate_models)\n",
        "        * [Without Scaling](#evaluate_models)    \n",
        "* [Compare and Select the Best Model](#compare_select)             \n",
        "* [Analysis](#load_datasets)\n",
        "* [Summary](#summary)\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "089c8cc2",
      "metadata": {
        "id": "089c8cc2"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, RandomizedSearchCV\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from sklearn.model_selection import TimeSeriesSplit\n",
        "from scipy.stats import randint\n",
        "import scipy.sparse\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2f2a4ea9-e0b3-4699-9f5b-f1ee5aafae11",
      "metadata": {
        "id": "2f2a4ea9-e0b3-4699-9f5b-f1ee5aafae11"
      },
      "source": [
        "## Load the Datasets <a id=\"load_datasets\"></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9e4a8d7d",
      "metadata": {
        "id": "9e4a8d7d"
      },
      "source": [
        "### Load X_train (no scaling) <a id=\"load_x_no_scaling\"></a>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "192db372",
      "metadata": {
        "id": "192db372",
        "outputId": "5f499743-8d29-4f0c-c9c7-0e6936ab4d4b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of columns: 589\n",
            "Number of rows: 2885062\n"
          ]
        }
      ],
      "source": [
        "# Load the sparse matrix (X_train_scaled)\n",
        "sparse_matrix_X_no_scaling = scipy.sparse.load_npz('C:/Users/midol/Documents/Springboard/Springboard/Capstone_2/Erasmus/X_train_sparse_no_scaling.npz')\n",
        "\n",
        "# Load the columns/index\n",
        "columns = pd.read_csv('C:/Users/midol/Documents/Springboard/Springboard/Capstone_2/Erasmus/X_train_sparse_no_scaling_columns.csv', header=None)\n",
        "index = pd.read_csv('C:/Users/midol/Documents/Springboard/Springboard/Capstone_2/Erasmus/X_train_sparse_no_scaling_index.csv', header=None)\n",
        "\n",
        "# Convert columns/index to lists\n",
        "columns = columns.iloc[:, 0].tolist()\n",
        "index = index.iloc[:, 0].tolist()\n",
        "\n",
        "# Print lengths of columns and index\n",
        "print(\"Number of columns:\", len(columns))\n",
        "print(\"Number of rows:\", len(index))\n",
        "\n",
        "# Convert the sparse matrix back to a sparse DataFrame\n",
        "X_train_no_scaling = pd.DataFrame.sparse.from_spmatrix(sparse_matrix_X_no_scaling, index=index, columns=columns)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cb6e6c44",
      "metadata": {
        "id": "cb6e6c44"
      },
      "source": [
        "### Load X_train (scaled) <a id=\"load_x_scaled\"></a>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bc70cf32",
      "metadata": {
        "id": "bc70cf32",
        "outputId": "791d308d-3e3b-4055-af92-a9b16a262865"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of columns: 589\n",
            "Number of rows: 2885062\n"
          ]
        }
      ],
      "source": [
        "# Load the sparse matrix (X_train_scaled)\n",
        "sparse_matrix_X_train_scaled = scipy.sparse.load_npz('C:/Users/midol/Documents/Springboard/Springboard/Capstone_2/Erasmus/X_train_sparse_scaled.npz')\n",
        "\n",
        "# Load the columns/index\n",
        "columns = pd.read_csv('C:/Users/midol/Documents/Springboard/Springboard/Capstone_2/Erasmus/X_train_sparse_scaled_columns.csv', header=None)\n",
        "index = pd.read_csv('C:/Users/midol/Documents/Springboard/Springboard/Capstone_2/Erasmus/X_train_sparse_scaled_index.csv', header=None)\n",
        "\n",
        "# Convert columns/index to lists\n",
        "columns = columns.iloc[:, 0].tolist()\n",
        "index = index.iloc[:, 0].tolist()\n",
        "\n",
        "# Print lengths of columns and index\n",
        "print(\"Number of columns:\", len(columns))\n",
        "print(\"Number of rows:\", len(index))\n",
        "\n",
        "# Convert the sparse matrix back to a sparse DataFrame\n",
        "X_train_scaled = pd.DataFrame.sparse.from_spmatrix(sparse_matrix_X_train_scaled, index=index, columns=columns)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b2dedb60",
      "metadata": {
        "id": "b2dedb60"
      },
      "source": [
        "### Load X_test <a id=\"y_train\"></a>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fa3fa3fe",
      "metadata": {
        "id": "fa3fa3fe",
        "outputId": "63fdf71b-7d1e-4d4f-9089-b08e4f92c098"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of columns: 589\n",
            "Number of rows: 577012\n"
          ]
        }
      ],
      "source": [
        "# Load the sparse matrix (X_scaled)\n",
        "sparse_matrix_X_test = scipy.sparse.load_npz('C:/Users/midol/Documents/Springboard/Springboard/Capstone_2/Erasmus/X_test.npz')\n",
        "\n",
        "# Load the columns/index\n",
        "columns = pd.read_csv('C:/Users/midol/Documents/Springboard/Springboard/Capstone_2/Erasmus/X_test_columns.csv', header=None)\n",
        "index = pd.read_csv('C:/Users/midol/Documents/Springboard/Springboard/Capstone_2/Erasmus/X_test_index.csv', header=None)\n",
        "\n",
        "# Convert columns/index to lists\n",
        "columns = columns.iloc[:, 0].tolist()\n",
        "index = index.iloc[:, 0].tolist()\n",
        "\n",
        "# Print lengths of columns and index\n",
        "print(\"Number of columns:\", len(columns))\n",
        "print(\"Number of rows:\", len(index))\n",
        "\n",
        "# Convert the sparse matrix back to a sparse DataFrame\n",
        "X_test = pd.DataFrame.sparse.from_spmatrix(sparse_matrix_X_test, index=index, columns=columns)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "040b5e7b",
      "metadata": {
        "id": "040b5e7b"
      },
      "source": [
        "### Load y_train <a id=\"y_train\"></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d73011eb",
      "metadata": {
        "id": "d73011eb",
        "outputId": "e6c6f340-d511-4a6b-85df-59c691022afd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "2885062"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Load the dataset\n",
        "y_train = pd.read_csv('C:/Users/midol/Documents/Springboard/Springboard/Capstone_2/Erasmus/y_train.csv')\n",
        "\n",
        "len(y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "83e68aa5",
      "metadata": {
        "id": "83e68aa5"
      },
      "source": [
        "### Load y_test <a id=\"y_test\"></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "721f924a",
      "metadata": {
        "id": "721f924a",
        "outputId": "6e98b1c9-d56a-4576-bdd0-015b0be81578"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "577012"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Load the dataset\n",
        "y_test = pd.read_csv('C:/Users/midol/Documents/Springboard/Springboard/Capstone_2/Erasmus/y_test.csv')\n",
        "\n",
        "len(y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8fa40c50",
      "metadata": {
        "id": "8fa40c50"
      },
      "source": [
        "## Linear Regression <a id=\"random_forest\"></a>\n",
        "\n",
        "### Define the Models and Hyperparameters <a id=\"models_hyperparameters\"></a>\n",
        "\n",
        "We would have liked to do a thorough tuning of parameters:\n",
        "-  `'fit_intercept': [True, False]`\n",
        "-  `'copy_X': [True, False]`\n",
        "-  `'n_jobs': [None, 1, 2, -1]`\n",
        "\n",
        "However, the processing time required is excessive so we reduce to the following:\n",
        "- `fit_intercept`: This is an important parameter that can affect model bias, so we keep both True and False.\n",
        "- `copy_X`: This parameter is usually set to True, and changing it might not significantly impact the results for most use cases, so we only use True.\n",
        "- `n_jobs`: This parameter influences computation time but not the learning process, so we use -1 to make use of all available CPU cores."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8e36cbb0",
      "metadata": {
        "id": "8e36cbb0"
      },
      "outputs": [],
      "source": [
        "# Linear Regression\n",
        "lr = LinearRegression()\n",
        "lr_params = {\n",
        "    'fit_intercept': [True, False],\n",
        "    'copy_X': [True],\n",
        "    'n_jobs': [-1]\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a8b56346",
      "metadata": {
        "id": "a8b56346"
      },
      "source": [
        "### Tune the Hyperparameters <a id=\"tune_hyperparameters\"></a>\n",
        "\n",
        "Given the size of our dataset, we use RandomizedSearchCV for hyperparameter tuning with cross-validation.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4647675c",
      "metadata": {
        "id": "4647675c"
      },
      "outputs": [],
      "source": [
        "# Instantiate TimeSeriesSplit\n",
        "tscv = TimeSeriesSplit(n_splits=5)\n",
        "\n",
        "# Linear Regression randomized search with cross-validation\n",
        "lr_random_search = RandomizedSearchCV(estimator=lr, param_distributions=lr_params, n_iter=5, cv=tscv, scoring='neg_mean_squared_error', random_state=42, n_jobs=-1)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e2028795",
      "metadata": {
        "id": "e2028795"
      },
      "source": [
        "#### Fit without Scaling <a id=\"tune_hyperparameters\"></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7b5ab899-8d87-49de-8c08-36699f863271",
      "metadata": {
        "id": "7b5ab899-8d87-49de-8c08-36699f863271"
      },
      "outputs": [],
      "source": [
        "# Non-scaled\n",
        "lr_random_search.fit(X_train_no_scaling, y_train)\n",
        "\n",
        "# Output the best parameters\n",
        "lr_best_params_no_scaling = lr_random_search.best_params_\n",
        "print(\"Best Parameters from RandomizedSearchCV for lr NO SCALING\", lr_best_params_no_scaling)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e9f71cac",
      "metadata": {
        "id": "e9f71cac"
      },
      "source": [
        "#### Fit with Scaling <a id=\"tune_hyperparameters\"></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fdc86fd0-0510-4629-8c8d-ff4214a6a968",
      "metadata": {
        "id": "fdc86fd0-0510-4629-8c8d-ff4214a6a968"
      },
      "outputs": [],
      "source": [
        "# Scaled\n",
        "lr_random_search.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Output the best parameters\n",
        "lr_best_params_scaled = lr_random_search.best_params_\n",
        "print(\"Best Parameters from RandomizedSearchCV lr SCALED\", lr_best_params_scaled)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e1545bf6",
      "metadata": {
        "id": "e1545bf6"
      },
      "source": [
        "## Random Forest Regressor <a id=\"random_forest\"></a>\n",
        "\n",
        "### Define the Models and Hyperparameters <a id=\"models_hyperparameters\"></a>\n",
        "\n",
        "We define the Random Forest Regression model and set up the hyperparameters.\n",
        "\n",
        "\n",
        "\n",
        "Likewise, we would have preferred doing a thorough tuning of parameters:\n",
        "-  `'n_estimators': [100, 200, 300]`\n",
        "-  `'max_depth': [None, 10, 20, 30]`\n",
        "-  `'min_samples_split': [2, 5, 10]`\n",
        "\n",
        "However, the processing time required is excessive so we reduce to the following:\n",
        "\n",
        "- `n_estimators`: Controls the number of trees in the forest. We reduce to 100 and 200 for quicker evaluations.\n",
        "- `max_depth`: Controls the maximum depth of the tree. None (nodes are expanded until all leaves are pure) might often be the best choice, but we keep 10 and 20 to prevent overfitting.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "79188255",
      "metadata": {
        "id": "79188255"
      },
      "outputs": [],
      "source": [
        "# Random Forest Regressor\n",
        "rf = RandomForestRegressor(random_state=42)\n",
        "random_params = {\n",
        "    'n_estimators': [100, 200],\n",
        "    'max_features': ['log2'],\n",
        "    'max_depth': [10, 20],\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1a66c255",
      "metadata": {
        "id": "1a66c255"
      },
      "source": [
        "### Tune the Hyperparameters <a id=\"tune_hyperparameters\"></a>\n",
        "\n",
        "Given the size of our dataset, we use RandomizedSearchCV for hyperparameter tuning with cross-validation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5532f7fa",
      "metadata": {
        "id": "5532f7fa"
      },
      "outputs": [],
      "source": [
        "# Instantiate TimeSeriesSplit\n",
        "tscv = TimeSeriesSplit(n_splits=5)\n",
        "\n",
        "# Random Forest Regressor randomized search with cross-validation\n",
        "rf_random_search = RandomizedSearchCV(estimator=rf, param_distributions=random_params, n_iter=2, cv=tscv, scoring='neg_mean_squared_error', random_state=42, n_jobs=-1)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7fd7e1ba",
      "metadata": {
        "id": "7fd7e1ba"
      },
      "source": [
        "#### Fit with Scaling <a id=\"tune_hyperparameters\"></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3f7c8083-6dd2-4d0b-b85d-42500efbc9a6",
      "metadata": {
        "id": "3f7c8083-6dd2-4d0b-b85d-42500efbc9a6"
      },
      "outputs": [],
      "source": [
        "# Scaled\n",
        "rf_random_search.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Output the best parameters\n",
        "random_best_params_scaled = rf_random_search.best_params_\n",
        "print(\"Best Parameters from RandomizedSearchCV:\", random_best_params_scaled)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cdde75fc",
      "metadata": {
        "id": "cdde75fc"
      },
      "source": [
        "#### Fit without Scaling <a id=\"tune_hyperparameters\"></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9efef1e8-dd04-46d7-beec-9a97aef97800",
      "metadata": {
        "id": "9efef1e8-dd04-46d7-beec-9a97aef97800"
      },
      "outputs": [],
      "source": [
        "# Non-scaled\n",
        "rf_random_search.fit(X_train_no_scaling, y_train)\n",
        "\n",
        "# Output the best parameters\n",
        "random_best_params_no_scaling = rf_random_search.best_params_\n",
        "print(\"Best Parameters from RandomizedSearchCV random NO SCALING:\", random_best_params_no_scaling)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a96cd075",
      "metadata": {
        "id": "a96cd075"
      },
      "source": [
        "## Evaluate the Models <a id=\"evaluate_models\"></a>\n",
        "\n",
        "Then we evaluate the models using the best hyperparameters on the test set."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4650d927",
      "metadata": {
        "id": "4650d927"
      },
      "source": [
        "### Linear Regression <a id=\"linear_regression3\"></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e3cd87fc",
      "metadata": {
        "id": "e3cd87fc"
      },
      "outputs": [],
      "source": [
        "# Linear Regression Evaluation\n",
        "best_lr = lr_grid.best_estimator_\n",
        "y_pred_lr = best_lr.predict(X_test)\n",
        "\n",
        "# Evaluation Metrics\n",
        "mse_lr = mean_squared_error(y_test, y_pred_lr)\n",
        "r2_lr = r2_score\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "331a2f20",
      "metadata": {
        "id": "331a2f20"
      },
      "source": [
        "### Random Forest Regressor <a id=\"random_forest3\"></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "63062eb8",
      "metadata": {
        "id": "63062eb8"
      },
      "outputs": [],
      "source": [
        "# Random Forest Evaluation\n",
        "best_rf = rf_grid.best_estimator_\n",
        "y_pred_rf = best_rf.predict(X_test)\n",
        "\n",
        "# Evaluation Metrics\n",
        "mse_rf = mean_squared_error(y_test, y_pred_rf)\n",
        "r2_rf = r2_score(y_test, y_pred_rf)\n",
        "\n",
        "print(\"Random Forest Performance:\")\n",
        "print(\"MSE:\", mse_rf)\n",
        "print(\"R^2 Score:\", r2_rf)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "60ea7e50",
      "metadata": {
        "id": "60ea7e50"
      },
      "source": [
        "## Compare and Select the Best Model <a id=\"compare_select\"></a>\n",
        "\n",
        "Finally, we compare the performance metrics and choose the best model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d14e0cab",
      "metadata": {
        "id": "d14e0cab"
      },
      "outputs": [],
      "source": [
        "print(\"\\nComparison:\")\n",
        "if mse_lr < mse_rf:\n",
        "    print(\"Best Model: Linear Regression\")\n",
        "    best_model = best_lr\n",
        "    best_mse = mse_lr\n",
        "    best_r2 = r2_lr\n",
        "else:\n",
        "    print(\"Best Model: Random Forest\")\n",
        "    best_model = best_rf\n",
        "    best_mse = mse_rf\n",
        "    best_r2 = r2_rf\n",
        "\n",
        "print(\"\\nBest Model Performance:\")\n",
        "print(\"MSE:\", best_mse)\n",
        "print(\"R^2 Score:\", best_r2)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1cc76418",
      "metadata": {
        "id": "1cc76418"
      },
      "source": [
        "## Run the Analysis <a id=\"run_analysis\"></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6a03bb2c",
      "metadata": {
        "id": "6a03bb2c"
      },
      "outputs": [],
      "source": [
        "# REPLACE WITH THE BEST MODEL!!!!!\n",
        "\n",
        "# Fit the model on the entire training data\n",
        "best_rf = random_search.best_estimator_\n",
        "best_rf.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred = best_rf.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0f9972ae",
      "metadata": {
        "id": "0f9972ae"
      },
      "outputs": [],
      "source": [
        "# Calculate and print the mean squared error\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "print(f\"Mean Squared Error on test set: {mse:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4af75f44",
      "metadata": {
        "id": "4af75f44"
      },
      "source": [
        "## Summary <a id=\"summary\"></a>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a1b12318-d261-4b05-9c35-1e86c710f972",
      "metadata": {
        "id": "a1b12318-d261-4b05-9c35-1e86c710f972"
      },
      "source": [
        "Unfortunately, the memory required to run this final notebook is more than my equipment can handle. The following options were investigated and attempted unsuccessfully:\n",
        "- Run on Google Colab\n",
        "- Use Dask\n",
        "- Convert data to sparse format\n",
        "- Reduce hyperparameters to a minimum\n",
        "- Run hyperparameter tuning on one split of the data only\n",
        "- Use RandomizedSearchCV rather than GridSearch\n",
        "\n",
        "We loaded our data, previously split using TimeSeriesSplit since our data has a temporal element.\n",
        "We defined the models and hyperparameters for two models: Linear Regression and Random Forest Regressor.\n",
        "We prepared to tune the hyperparameters of both models, using RandomizedSearchCV, evaluating both X_train scaled and unscaled.\n",
        "Finally, we prepared to evaluate the models using evaluation metrics mean squared error and R2. Based on these results, we would have chosen the best model and run our analysis.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0216e6a1-f6d3-4605-85ae-d31dcc53f472",
      "metadata": {
        "id": "0216e6a1-f6d3-4605-85ae-d31dcc53f472"
      },
      "source": [
        "## Recommendations <a id=\"summary\"></a>\n",
        "\n",
        "Despite the inability to run the final analysis, we can propose recommendations on how the client could utilize the results if a conclusive analysis had been possible:\n",
        "\n",
        "**1. Strategic Allocation Planning**:\n",
        "- By identifying which countries are most likely to need or receive future funds, the Erasmus program can strategically plan its budget allocations. Countries receiving consistent funding could be highlighted for more detailed reviews to ensure alignment with Erasmus objectives.\n",
        "- Recognizing underfunded countries with potential growth can lead to proactive support and development initiatives, ensuring a balanced distribution of educational opportunities across Europe.\n",
        "\n",
        "**2. Targeted Program Development**:\n",
        "- With insights into participant demographics and project types, Erasmus can design targeted programs addressing specific needs, such as increasing male participation or supporting countries with lower project durations.\n",
        "- By understanding the funding patterns and areas of high impact, Erasmus can develop specialized workshops, training sessions, or partnerships tailored to enhance the projects' effectiveness in those regions.\n",
        "\n",
        "**3. Policy and Engagement Strategies**:\n",
        "- Leveraging the trends and predictive analytics, policymakers can be better equipped to advocate for continuous or increased funding in certain regions, potentially adjusting policy to support high-engagement programs.\n",
        "- Engagement strategies could be refined by focusing marketing and informational campaigns in countries identified to have growing or high participant interest . Highlighting successful projects from previous years can serve as inspiration and motivation for new participants and organizations.\n",
        "\n",
        "**Conclusion**\n",
        "\n",
        "Although we faced technical limitations that prevented us from performing the final analysis, the preparatory work and exploratory analysis provided valuable insights into Erasmus program funding and participation trends. By addressing memory constraints, future iterations of this analysis could provide far more detailed and actionable insights.\n",
        "\n",
        "By formalizing these steps, Erasmus can harness data-driven decision-making to support and expand transnational education, training, youth, and sport initiatives effectively.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cbb1cbb3-0e0c-4eee-bcb1-877f711ff7f8",
      "metadata": {
        "id": "cbb1cbb3-0e0c-4eee-bcb1-877f711ff7f8"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}